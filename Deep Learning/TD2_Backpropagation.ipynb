{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TD2_Backpropagation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qQ9kk0EoK29d"},"source":["# Week 2"]},{"cell_type":"markdown","metadata":{"id":"6_2kVYDmzImz"},"source":["Exo 1"]},{"cell_type":"code","metadata":{"id":"sNQygJslvSvd","executionInfo":{"status":"ok","timestamp":1612946628460,"user_tz":-60,"elapsed":1315,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["# Initialize a network\n","from random import random\n","def initialize_network(n_inputs , n_hidden , n_outputs):\n","  network = list()\n","  hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)] \n","  network.append(hidden_layer)\n","  output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)] # output layer should be defined here\n","  network.append(output_layer)#output layer should be added to the network here\n","  return network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"glVNKDqE7TEt"},"source":["Exo2"]},{"cell_type":"code","metadata":{"id":"le_WCkhu7_HY","executionInfo":{"status":"ok","timestamp":1612946631828,"user_tz":-60,"elapsed":919,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["from random import seed\n","seed(703185)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iIVM2iT1F0l","executionInfo":{"status":"ok","timestamp":1612946634221,"user_tz":-60,"elapsed":428,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"178e6c66-8b37-4092-e9f7-2ee28ca2b363"},"source":["initialize_network(2,3,1)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[{'weights': [0.9891032530590325, 0.0265960175075014, 0.5796018782649225]},\n","  {'weights': [0.3725427863726888, 0.5542717635140079, 0.6006422923773905]},\n","  {'weights': [0.3568641403648303, 0.5616733148741453, 0.7145775125959037]}],\n"," [{'weights': [0.9328072439242623,\n","    0.4400213857630133,\n","    0.015970702885971688,\n","    0.24748356156372875]}]]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"e8zFNMl42uJv"},"source":["Network : hidden_layer composé de 3 n_hidden neurons , eux même composé 3 n_inputs+1 weights. Output_layer composé d'1 n_output neuron, lui même composé de 4 n_hidden + 1 weights. "]},{"cell_type":"markdown","metadata":{"id":"4hL3Gngy8F4m"},"source":["EXO 3"]},{"cell_type":"code","metadata":{"id":"QBTNstWy7UWa","executionInfo":{"status":"ok","timestamp":1612946637606,"user_tz":-60,"elapsed":442,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["# Calculate neuron activation for an input\n","#for the hidden layer, input can be a row from training set, and for output layer, it's the output of each neuron in the hidden layer\n","def activate(weights, inputs):\n","  activation = weights[-1]\n","  for i in range(len(inputs)):\n","    activation += (weights[i] * inputs[i]) \n","  return activation"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0I6-_9-JAfMG"},"source":["EXO 4"]},{"cell_type":"code","metadata":{"id":"6hNtJL-G_dli","executionInfo":{"status":"ok","timestamp":1612946639444,"user_tz":-60,"elapsed":466,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#Here we proceed to the transfer of the activation function to see what is the output of the neuron. Different transfer function are possibel. Here we will use\n","#the sigmoid function (S shape, alternante between 0 and 1)\n","from math import exp\n","def transfer(activation):\n","  return 1.0/(1.0 + exp(-activation))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZWa1RF3AryW"},"source":["EXO 5"]},{"cell_type":"code","metadata":{"id":"cZOLhm6mAsnD","executionInfo":{"status":"ok","timestamp":1612946641332,"user_tz":-60,"elapsed":631,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["# Forward propagate input to a network output\n","#In this function, we calculate the output of a layer's neuron and then the value is stored and become the input for the next layer, and that\n","#until the final layer is done\n","def forward_propagate(network, row):\n","\tinputs = row\n","\tfor layer in network:\n","\t\tnew_inputs = []\n","\t\tfor neuron in layer:\n","\t\t\tactivation = activate(neuron['weights'], inputs)\n","\t\t\tneuron['output'] = transfer(activation)\n","\t\t\tnew_inputs.append(neuron['output'])\n","\t\tinputs = new_inputs\n","\treturn inputs"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SADW3IMeBjNX"},"source":["EXO 6"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ch6Ws5H-Bhr_","executionInfo":{"status":"ok","timestamp":1612946642644,"user_tz":-60,"elapsed":490,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"edc07cd3-3e37-490c-e162-c5a9ff500191"},"source":["#test forward propagation\n","network = initialize_network(2,3,1)\n","#the size of the row should be the same as the number of inputs\n","row=[1, 0]\n","output = forward_propagate(network, row)\n","print(network)\n","#Because the output layer has one neuron, we only get one final output value\n","#For now the value doesn't make any sense, but we will change that after"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[{'weights': [0.23836526091710708, 0.2414349845019762, 0.7822916156831258], 'output': 0.7351005313146323}, {'weights': [0.4414340101310036, 0.1438043630364002, 0.650789866397262], 'output': 0.7488002606967885}, {'weights': [0.5545772882836295, 0.5066019392894244, 0.10618567280784674], 'output': 0.6594317562461762}], [{'weights': [0.8480340705380638, 0.08919185231320548, 0.9851981503634689, 0.10273410954913431], 'output': 0.8088542067242253}]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MiK7pONrQbUO"},"source":["We will now work on back propagate error\n","Error is calculated bewteen expected output and what we got, and then this error backpropagate the neural network in a way that able us to change the weight.\n","\n","Two steps : \n","Transfer Derivative.\n","Error Backpropagation."]},{"cell_type":"markdown","metadata":{"id":"HQv7EAb2Eul-"},"source":["EXO 7"]},{"cell_type":"code","metadata":{"id":"u6_qDFqnD55d","executionInfo":{"status":"ok","timestamp":1612946644389,"user_tz":-60,"elapsed":432,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#First we need to calculate the derivative, the slope of the output of a neuron\n","def transfer_derivative(output):\n","  return output * (1.0 - output)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bwGV3BPIFQtM"},"source":["EXO 8"]},{"cell_type":"code","metadata":{"id":"pYAnGH_VFPvO","executionInfo":{"status":"ok","timestamp":1612946646059,"user_tz":-60,"elapsed":457,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#Then we apply the error backpropagation\n","#We have to calculate the error for each output neuron\n","def backward_propagate_error(network, expected):\n","  for i in reversed(range(len(network))):\n","    layer = network[i]\n","    errors = list()\n","    if i != len(network) -1 :\n","      for j in range(len(layer)):\n","        error = 0.0 \n","        for neuron in network[i + 1]:\n","          error += (neuron['weights'][j] * neuron['delta'])\n","        errors.append(error)\n","    else : \n","      for j in range(len(layer)):\n","        neuron = layer[j]\n","        errors.append(expected[j] - neuron['output'])\n","    for j in range(len(layer)):\n","      neuron = layer[j]\n","      neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n","#You can see that the error signal calculated for each neuron is stored with the name ‘delta’. \n","#You can see that the layers of the network are iterated in reverse order, starting at the output \n","#and working backwards. This ensures that the neurons in the output layer have ‘delta’ values calculated \n","#first that neurons in the hidden layer can use in the subsequent iteration. We chose the name ‘delta’ \n","#to reflect the change the error implies on the neuron (e.g. the weight delta).\n","\n","#You can see that the error signal for neurons in the hidden layer is accumulated from neurons \n","#in the output layer where the hidden neuron number j is also the index of the neuron’s weight in the output layer neuron[‘weights’][j]."],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8YXPW4ARH69v"},"source":["EXO 9"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjlbHzpTHinM","executionInfo":{"status":"ok","timestamp":1612946648089,"user_tz":-60,"elapsed":419,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"c12c84d7-d83e-42a2-f1fd-2f17e36c3997"},"source":["#test backward_propagate_error\n","network = initialize_network(2,3,1)\n","row=[1, 0]\n","forward_propagate(network, row)\n","expected=[1]#size of expected is one because one neuron in the output layer\n","backward_propagate_error(network, expected)\n","for layer in network:\n","  print(layer)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[{'weights': [0.2500693907068773, 0.7973015217513506, 0.2399732077762381], 'output': 0.6201164674057597, 'delta': 0.0022254285009697455}, {'weights': [0.4538364070934504, 0.709371778077704, 0.7793992434087644], 'output': 0.7743843869908983, 'delta': 0.0038710403746963257}, {'weights': [0.293906706774522, 0.8936999734100869, 0.337273872602442], 'output': 0.6527571067680923, 'delta': 0.0011091467988885474}]\n","[{'weights': [0.14021541053419517, 0.32885753479350666, 0.07262897073802954, 0.39613582484477694], 'output': 0.686790484134991, 'delta': 0.0673742844206721}]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5QYPn-4QaqNx"},"source":["Running the example prints the network after the backpropagation of error is complete. You can see that error values (delta) are calculated and stored in the neurons for the output layer and the hidden layer.\n"]},{"cell_type":"markdown","metadata":{"id":"mFnj5ywa4b4M"},"source":["EXO 10"]},{"cell_type":"code","metadata":{"id":"MBUoVEta7IsT","executionInfo":{"status":"ok","timestamp":1612946650438,"user_tz":-60,"elapsed":415,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#We will now use the error to update the weights\n","#weight = weight + learning_rate * error * input (weight : given weight, lr : we will specify it later, error : the one we calculated, input : input that caused the error)\n","def update_weights(network, row, l_rate):\n","\tfor i in range(len(network)):\n","   #input for first layer when i = 0\n","\t\tinputs = row[:-1]\n","    #then input of other layer is output of previous layer\n","\t\tif i != 0:\n","\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n","\t\tfor neuron in network[i]:\n","\t\t\tfor j in range(len(inputs)):\n","\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j] #=> weight = weight + learning_rate * error * input\n","\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n","\n","#we now have to do it repeatedly"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TrEePZV7865S"},"source":["EXO 11"]},{"cell_type":"code","metadata":{"id":"UrFcQfNc87ms","executionInfo":{"status":"ok","timestamp":1612946652188,"user_tz":-60,"elapsed":503,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#We create a function that involves looping for a number of epochs and for each epochs update the network\n","#This function take as parameters an initialized neural network, a training dataset, learning rate, number of epochs and expected number of value\n","def train_network(network, train, l_rate, n_epoch, n_outputs):\n","\tfor epoch in range(n_epoch):\n","\t\tsum_error = 0\n","\t\tfor row in train:\n","\t\t\toutputs = forward_propagate(network, row) #because forward propagate calculate the output of a neuron\n","\t\t\texpected = [0 for i in range(n_outputs)]\n","\t\t\texpected[row[-1]] = 1\n","\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))]) #formula for the mean square error\n","\t\t\tbackward_propagate_error(network, expected) #we add delta to the network\n","\t\t\tupdate_weights(network, row, l_rate) #we modify weights\n","\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8KQ4ocut_CEl"},"source":["EXO 12"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vsmjqtxq878I","executionInfo":{"status":"ok","timestamp":1612946654023,"user_tz":-60,"elapsed":404,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"250afa25-665c-4882-bf1a-87cbb09abbdf"},"source":["#We will now test the complete code with a small dataset\n","dataset = [[2.7810836,2.550537003,0],\n","\t[1.465489372,2.362125076,0],\n","\t[3.396561688,4.400293529,0],\n","\t[1.38807019,1.850220317,0],\n","\t[3.06407232,3.005305973,0],\n","\t[7.627531214,2.759262235,1],\n","\t[5.332441248,2.088626775,1],\n","\t[6.922596716,1.77106367,1],\n","\t[8.675418651,-0.242068655,1],\n","\t[7.673756466,3.508563011,1]]\n","\n","n_inputs = 2 #because we have two variables one target\n","n_output = 2 #because classification problem with two possible solution\n","n_hidden = 2 #because we choose to do so\n","epochs = 20\n","lr = 0.5\n","\n","network = initialize_network(n_inputs, n_hidden, n_output)\n","train_network(network, dataset, lr, epochs, n_output)"],"execution_count":13,"outputs":[{"output_type":"stream","text":[">epoch=0, lrate=0.500, error=7.138\n",">epoch=1, lrate=0.500, error=6.058\n",">epoch=2, lrate=0.500, error=5.476\n",">epoch=3, lrate=0.500, error=5.363\n",">epoch=4, lrate=0.500, error=5.363\n",">epoch=5, lrate=0.500, error=5.369\n",">epoch=6, lrate=0.500, error=5.369\n",">epoch=7, lrate=0.500, error=5.365\n",">epoch=8, lrate=0.500, error=5.357\n",">epoch=9, lrate=0.500, error=5.345\n",">epoch=10, lrate=0.500, error=5.329\n",">epoch=11, lrate=0.500, error=5.303\n",">epoch=12, lrate=0.500, error=5.263\n",">epoch=13, lrate=0.500, error=5.195\n",">epoch=14, lrate=0.500, error=5.078\n",">epoch=15, lrate=0.500, error=4.900\n",">epoch=16, lrate=0.500, error=4.690\n",">epoch=17, lrate=0.500, error=4.460\n",">epoch=18, lrate=0.500, error=4.202\n",">epoch=19, lrate=0.500, error=3.920\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXUCdv8LAFRN","executionInfo":{"status":"ok","timestamp":1612946657518,"user_tz":-60,"elapsed":417,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"c57a0f03-d3d6-4688-d026-1f42d1546586"},"source":["for layer in network : \n","  print(layer)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[{'weights': [0.8315036465899801, -0.9184614943867463, -0.06290015041559557], 'output': 0.9365526598756515, 'delta': 0.009303188921946488}, {'weights': [0.4079176766138058, 0.9737203488590528, 1.019046018443257], 'output': 0.9998131395665123, 'delta': -6.818419278647324e-06}]\n","[{'weights': [-1.1044889422365014, 0.2055970442028343, 0.03223667200679335], 'output': 0.33409914062296053, 'delta': -0.07432934272150052}, {'weights': [1.0594151099315132, -0.20765794520283176, 0.0011683949951532824], 'output': 0.6631878277213094, 'delta': 0.07523364495383629}]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4AoqrsStElAd"},"source":["We can clearly see that the error (delta) has decreased a lot"]},{"cell_type":"markdown","metadata":{"id":"2wH96FRvFWYK"},"source":["EXO 13 - Predict"]},{"cell_type":"code","metadata":{"id":"jv2w-k91AGg3","executionInfo":{"status":"ok","timestamp":1612946660612,"user_tz":-60,"elapsed":527,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#For now, we just worked on training de neural network.\n","#We will now work on a predict function, function that just call the forward_propagate function because it's all we need to make a first prediction\n","#So this procedure return the index of the output with the bigger probability\n","\n","def predict(network, row):\n","\toutputs = forward_propagate(network, row)\n","\treturn outputs.index(max(outputs))"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sAJuAVAaHWl6"},"source":["EXO 14"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaXDoSFqHXKd","executionInfo":{"status":"ok","timestamp":1612946675740,"user_tz":-60,"elapsed":427,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"e2c4a050-2161-4ed9-d193-eee93fc0fc0d"},"source":["#Lets test the predict function\n","seed(79787)\n","dataset = [[2.7810836,2.550537003,0],\n","\t[1.465489372,2.362125076,0],\n","\t[3.396561688,4.400293529,0],\n","\t[1.38807019,1.850220317,0],\n","\t[3.06407232,3.005305973,0],\n","\t[7.627531214,2.759262235,1],\n","\t[5.332441248,2.088626775,1],\n","\t[6.922596716,1.77106367,1],\n","\t[8.675418651,-0.242068655,1],\n","\t[7.673756466,3.508563011,1]]\n","for row in dataset:\n","\tprediction = predict(network, row)\n","\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Expected=0, Got=1\n","Expected=0, Got=1\n","Expected=0, Got=1\n","Expected=0, Got=1\n","Expected=0, Got=1\n","Expected=1, Got=1\n","Expected=1, Got=1\n","Expected=1, Got=1\n","Expected=1, Got=1\n","Expected=1, Got=1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kP1OoYK0LbP4"},"source":["We do have 100% accuracy"]},{"cell_type":"markdown","metadata":{"id":"UXjC2omwMD2b"},"source":["EXO 16 - Get the dataset"]},{"cell_type":"code","metadata":{"id":"N155uLPist6v","executionInfo":{"status":"ok","timestamp":1612946830989,"user_tz":-60,"elapsed":422,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["from csv import reader\n","def load_csv(filename):\n","\tdataset = list()\n","\twith open(filename, 'r') as file:\n","    #we read the file\n","\t\tcsv_reader = reader(file)\n","\t\tfor row in csv_reader:\n","\t\t\tif not row:\n","\t\t\t\tcontinue\n","        #we travel the file, and for each row, we add them to a new list that will be our dataset\n","\t\t\tdataset.append(row)\n","\treturn dataset"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4nEs5lHKkw3","executionInfo":{"status":"ok","timestamp":1612946848977,"user_tz":-60,"elapsed":523,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"35b3cebc-bca3-40c8-9b01-443a3583cb86"},"source":["dataset = load_csv('/content/seeds_dataset-2.csv')\n","dataset\n","#we clearly have to clean the dataset first"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['15.26\\t14.84\\t0.871\\t5.763\\t3.312\\t2.221\\t5.22\\t1'],\n"," ['14.88\\t14.57\\t0.8811\\t5.554\\t3.333\\t1.018\\t4.956\\t1'],\n"," ['14.29\\t14.09\\t0.905\\t5.291\\t3.337\\t2.699\\t4.825\\t1'],\n"," ['13.84\\t13.94\\t0.8955\\t5.324\\t3.379\\t2.259\\t4.805\\t1'],\n"," ['16.14\\t14.99\\t0.9034\\t5.658\\t3.562\\t1.355\\t5.175\\t1'],\n"," ['14.38\\t14.21\\t0.8951\\t5.386\\t3.312\\t2.462\\t4.956\\t1'],\n"," ['14.69\\t14.49\\t0.8799\\t5.563\\t3.259\\t3.586\\t5.219\\t1'],\n"," ['14.11\\t14.1\\t0.8911\\t5.42\\t3.302\\t2.7\\t5\\t1'],\n"," ['16.63\\t15.46\\t0.8747\\t6.053\\t3.465\\t2.04\\t5.877\\t1'],\n"," ['16.44\\t15.25\\t0.888\\t5.884\\t3.505\\t1.969\\t5.533\\t1'],\n"," ['15.26\\t14.85\\t0.8696\\t5.714\\t3.242\\t4.543\\t5.314\\t1'],\n"," ['14.03\\t14.16\\t0.8796\\t5.438\\t3.201\\t1.717\\t5.001\\t1'],\n"," ['13.89\\t14.02\\t0.888\\t5.439\\t3.199\\t3.986\\t4.738\\t1'],\n"," ['13.78\\t14.06\\t0.8759\\t5.479\\t3.156\\t3.136\\t4.872\\t1'],\n"," ['13.74\\t14.05\\t0.8744\\t5.482\\t3.114\\t2.932\\t4.825\\t1'],\n"," ['14.59\\t14.28\\t0.8993\\t5.351\\t3.333\\t4.185\\t4.781\\t1'],\n"," ['13.99\\t13.83\\t0.9183\\t5.119\\t3.383\\t5.234\\t4.781\\t1'],\n"," ['15.69\\t14.75\\t0.9058\\t5.527\\t3.514\\t1.599\\t5.046\\t1'],\n"," ['14.7\\t14.21\\t0.9153\\t5.205\\t3.466\\t1.767\\t4.649\\t1'],\n"," ['12.72\\t13.57\\t0.8686\\t5.226\\t3.049\\t4.102\\t4.914\\t1'],\n"," ['14.16\\t14.4\\t0.8584\\t5.658\\t3.129\\t3.072\\t5.176\\t1'],\n"," ['14.11\\t14.26\\t0.8722\\t5.52\\t3.168\\t2.688\\t5.219\\t1'],\n"," ['15.88\\t14.9\\t0.8988\\t5.618\\t3.507\\t0.7651\\t5.091\\t1'],\n"," ['12.08\\t13.23\\t0.8664\\t5.099\\t2.936\\t1.415\\t4.961\\t1'],\n"," ['15.01\\t14.76\\t0.8657\\t5.789\\t3.245\\t1.791\\t5.001\\t1'],\n"," ['16.19\\t15.16\\t0.8849\\t5.833\\t3.421\\t0.903\\t5.307\\t1'],\n"," ['13.02\\t13.76\\t0.8641\\t5.395\\t3.026\\t3.373\\t4.825\\t1'],\n"," ['12.74\\t13.67\\t0.8564\\t5.395\\t2.956\\t2.504\\t4.869\\t1'],\n"," ['14.11\\t14.18\\t0.882\\t5.541\\t3.221\\t2.754\\t5.038\\t1'],\n"," ['13.45\\t14.02\\t0.8604\\t5.516\\t3.065\\t3.531\\t5.097\\t1'],\n"," ['13.16\\t13.82\\t0.8662\\t5.454\\t2.975\\t0.8551\\t5.056\\t1'],\n"," ['15.49\\t14.94\\t0.8724\\t5.757\\t3.371\\t3.412\\t5.228\\t1'],\n"," ['14.09\\t14.41\\t0.8529\\t5.717\\t3.186\\t3.92\\t5.299\\t1'],\n"," ['13.94\\t14.17\\t0.8728\\t5.585\\t3.15\\t2.124\\t5.012\\t1'],\n"," ['15.05\\t14.68\\t0.8779\\t5.712\\t3.328\\t2.129\\t5.36\\t1'],\n"," ['16.12\\t15\\t0.9\\t5.709\\t3.485\\t2.27\\t5.443\\t1'],\n"," ['16.2\\t15.27\\t0.8734\\t5.826\\t3.464\\t2.823\\t5.527\\t1'],\n"," ['17.08\\t15.38\\t0.9079\\t5.832\\t3.683\\t2.956\\t5.484\\t1'],\n"," ['14.8\\t14.52\\t0.8823\\t5.656\\t3.288\\t3.112\\t5.309\\t1'],\n"," ['14.28\\t14.17\\t0.8944\\t5.397\\t3.298\\t6.685\\t5.001\\t1'],\n"," ['13.54\\t13.85\\t0.8871\\t5.348\\t3.156\\t2.587\\t5.178\\t1'],\n"," ['13.5\\t13.85\\t0.8852\\t5.351\\t3.158\\t2.249\\t5.176\\t1'],\n"," ['13.16\\t13.55\\t0.9009\\t5.138\\t3.201\\t2.461\\t4.783\\t1'],\n"," ['15.5\\t14.86\\t0.882\\t5.877\\t3.396\\t4.711\\t5.528\\t1'],\n"," ['15.11\\t14.54\\t0.8986\\t5.579\\t3.462\\t3.128\\t5.18\\t1'],\n"," ['13.8\\t14.04\\t0.8794\\t5.376\\t3.155\\t1.56\\t4.961\\t1'],\n"," ['15.36\\t14.76\\t0.8861\\t5.701\\t3.393\\t1.367\\t5.132\\t1'],\n"," ['14.99\\t14.56\\t0.8883\\t5.57\\t3.377\\t2.958\\t5.175\\t1'],\n"," ['14.79\\t14.52\\t0.8819\\t5.545\\t3.291\\t2.704\\t5.111\\t1'],\n"," ['14.86\\t14.67\\t0.8676\\t5.678\\t3.258\\t2.129\\t5.351\\t1'],\n"," ['14.43\\t14.4\\t0.8751\\t5.585\\t3.272\\t3.975\\t5.144\\t1'],\n"," ['15.78\\t14.91\\t0.8923\\t5.674\\t3.434\\t5.593\\t5.136\\t1'],\n"," ['14.49\\t14.61\\t0.8538\\t5.715\\t3.113\\t4.116\\t5.396\\t1'],\n"," ['14.33\\t14.28\\t0.8831\\t5.504\\t3.199\\t3.328\\t5.224\\t1'],\n"," ['14.52\\t14.6\\t0.8557\\t5.741\\t3.113\\t1.481\\t5.487\\t1'],\n"," ['15.03\\t14.77\\t0.8658\\t5.702\\t3.212\\t1.933\\t5.439\\t1'],\n"," ['14.46\\t14.35\\t0.8818\\t5.388\\t3.377\\t2.802\\t5.044\\t1'],\n"," ['14.92\\t14.43\\t0.9006\\t5.384\\t3.412\\t1.142\\t5.088\\t1'],\n"," ['15.38\\t14.77\\t0.8857\\t5.662\\t3.419\\t1.999\\t5.222\\t1'],\n"," ['12.11\\t13.47\\t0.8392\\t5.159\\t3.032\\t1.502\\t4.519\\t1'],\n"," ['11.42\\t12.86\\t0.8683\\t5.008\\t2.85\\t2.7\\t4.607\\t1'],\n"," ['11.23\\t12.63\\t0.884\\t4.902\\t2.879\\t2.269\\t4.703\\t1'],\n"," ['12.36\\t13.19\\t0.8923\\t5.076\\t3.042\\t3.22\\t4.605\\t1'],\n"," ['13.22\\t13.84\\t0.868\\t5.395\\t3.07\\t4.157\\t5.088\\t1'],\n"," ['12.78\\t13.57\\t0.8716\\t5.262\\t3.026\\t1.176\\t4.782\\t1'],\n"," ['12.88\\t13.5\\t0.8879\\t5.139\\t3.119\\t2.352\\t4.607\\t1'],\n"," ['14.34\\t14.37\\t0.8726\\t5.63\\t3.19\\t1.313\\t5.15\\t1'],\n"," ['14.01\\t14.29\\t0.8625\\t5.609\\t3.158\\t2.217\\t5.132\\t1'],\n"," ['14.37\\t14.39\\t0.8726\\t5.569\\t3.153\\t1.464\\t5.3\\t1'],\n"," ['12.73\\t13.75\\t0.8458\\t5.412\\t2.882\\t3.533\\t5.067\\t1'],\n"," ['17.63\\t15.98\\t0.8673\\t6.191\\t3.561\\t4.076\\t6.06\\t2'],\n"," ['16.84\\t15.67\\t0.8623\\t5.998\\t3.484\\t4.675\\t5.877\\t2'],\n"," ['17.26\\t15.73\\t0.8763\\t5.978\\t3.594\\t4.539\\t5.791\\t2'],\n"," ['19.11\\t16.26\\t0.9081\\t6.154\\t3.93\\t2.936\\t6.079\\t2'],\n"," ['16.82\\t15.51\\t0.8786\\t6.017\\t3.486\\t4.004\\t5.841\\t2'],\n"," ['16.77\\t15.62\\t0.8638\\t5.927\\t3.438\\t4.92\\t5.795\\t2'],\n"," ['17.32\\t15.91\\t0.8599\\t6.064\\t3.403\\t3.824\\t5.922\\t2'],\n"," ['20.71\\t17.23\\t0.8763\\t6.579\\t3.814\\t4.451\\t6.451\\t2'],\n"," ['18.94\\t16.49\\t0.875\\t6.445\\t3.639\\t5.064\\t6.362\\t2'],\n"," ['17.12\\t15.55\\t0.8892\\t5.85\\t3.566\\t2.858\\t5.746\\t2'],\n"," ['16.53\\t15.34\\t0.8823\\t5.875\\t3.467\\t5.532\\t5.88\\t2'],\n"," ['18.72\\t16.19\\t0.8977\\t6.006\\t3.857\\t5.324\\t5.879\\t2'],\n"," ['20.2\\t16.89\\t0.8894\\t6.285\\t3.864\\t5.173\\t6.187\\t2'],\n"," ['19.57\\t16.74\\t0.8779\\t6.384\\t3.772\\t1.472\\t6.273\\t2'],\n"," ['19.51\\t16.71\\t0.878\\t6.366\\t3.801\\t2.962\\t6.185\\t2'],\n"," ['18.27\\t16.09\\t0.887\\t6.173\\t3.651\\t2.443\\t6.197\\t2'],\n"," ['18.88\\t16.26\\t0.8969\\t6.084\\t3.764\\t1.649\\t6.109\\t2'],\n"," ['18.98\\t16.66\\t0.859\\t6.549\\t3.67\\t3.691\\t6.498\\t2'],\n"," ['21.18\\t17.21\\t0.8989\\t6.573\\t4.033\\t5.78\\t6.231\\t2'],\n"," ['20.88\\t17.05\\t0.9031\\t6.45\\t4.032\\t5.016\\t6.321\\t2'],\n"," ['20.1\\t16.99\\t0.8746\\t6.581\\t3.785\\t1.955\\t6.449\\t2'],\n"," ['18.76\\t16.2\\t0.8984\\t6.172\\t3.796\\t3.12\\t6.053\\t2'],\n"," ['18.81\\t16.29\\t0.8906\\t6.272\\t3.693\\t3.237\\t6.053\\t2'],\n"," ['18.59\\t16.05\\t0.9066\\t6.037\\t3.86\\t6.001\\t5.877\\t2'],\n"," ['18.36\\t16.52\\t0.8452\\t6.666\\t3.485\\t4.933\\t6.448\\t2'],\n"," ['16.87\\t15.65\\t0.8648\\t6.139\\t3.463\\t3.696\\t5.967\\t2'],\n"," ['19.31\\t16.59\\t0.8815\\t6.341\\t3.81\\t3.477\\t6.238\\t2'],\n"," ['18.98\\t16.57\\t0.8687\\t6.449\\t3.552\\t2.144\\t6.453\\t2'],\n"," ['18.17\\t16.26\\t0.8637\\t6.271\\t3.512\\t2.853\\t6.273\\t2'],\n"," ['18.72\\t16.34\\t0.881\\t6.219\\t3.684\\t2.188\\t6.097\\t2'],\n"," ['16.41\\t15.25\\t0.8866\\t5.718\\t3.525\\t4.217\\t5.618\\t2'],\n"," ['17.99\\t15.86\\t0.8992\\t5.89\\t3.694\\t2.068\\t5.837\\t2'],\n"," ['19.46\\t16.5\\t0.8985\\t6.113\\t3.892\\t4.308\\t6.009\\t2'],\n"," ['19.18\\t16.63\\t0.8717\\t6.369\\t3.681\\t3.357\\t6.229\\t2'],\n"," ['18.95\\t16.42\\t0.8829\\t6.248\\t3.755\\t3.368\\t6.148\\t2'],\n"," ['18.83\\t16.29\\t0.8917\\t6.037\\t3.786\\t2.553\\t5.879\\t2'],\n"," ['18.85\\t16.17\\t0.9056\\t6.152\\t3.806\\t2.843\\t6.2\\t2'],\n"," ['17.63\\t15.86\\t0.88\\t6.033\\t3.573\\t3.747\\t5.929\\t2'],\n"," ['19.94\\t16.92\\t0.8752\\t6.675\\t3.763\\t3.252\\t6.55\\t2'],\n"," ['18.55\\t16.22\\t0.8865\\t6.153\\t3.674\\t1.738\\t5.894\\t2'],\n"," ['18.45\\t16.12\\t0.8921\\t6.107\\t3.769\\t2.235\\t5.794\\t2'],\n"," ['19.38\\t16.72\\t0.8716\\t6.303\\t3.791\\t3.678\\t5.965\\t2'],\n"," ['19.13\\t16.31\\t0.9035\\t6.183\\t3.902\\t2.109\\t5.924\\t2'],\n"," ['19.14\\t16.61\\t0.8722\\t6.259\\t3.737\\t6.682\\t6.053\\t2'],\n"," ['20.97\\t17.25\\t0.8859\\t6.563\\t3.991\\t4.677\\t6.316\\t2'],\n"," ['19.06\\t16.45\\t0.8854\\t6.416\\t3.719\\t2.248\\t6.163\\t2'],\n"," ['18.96\\t16.2\\t0.9077\\t6.051\\t3.897\\t4.334\\t5.75\\t2'],\n"," ['19.15\\t16.45\\t0.889\\t6.245\\t3.815\\t3.084\\t6.185\\t2'],\n"," ['18.89\\t16.23\\t0.9008\\t6.227\\t3.769\\t3.639\\t5.966\\t2'],\n"," ['20.03\\t16.9\\t0.8811\\t6.493\\t3.857\\t3.063\\t6.32\\t2'],\n"," ['20.24\\t16.91\\t0.8897\\t6.315\\t3.962\\t5.901\\t6.188\\t2'],\n"," ['18.14\\t16.12\\t0.8772\\t6.059\\t3.563\\t3.619\\t6.011\\t2'],\n"," ['16.17\\t15.38\\t0.8588\\t5.762\\t3.387\\t4.286\\t5.703\\t2'],\n"," ['18.43\\t15.97\\t0.9077\\t5.98\\t3.771\\t2.984\\t5.905\\t2'],\n"," ['15.99\\t14.89\\t0.9064\\t5.363\\t3.582\\t3.336\\t5.144\\t2'],\n"," ['18.75\\t16.18\\t0.8999\\t6.111\\t3.869\\t4.188\\t5.992\\t2'],\n"," ['18.65\\t16.41\\t0.8698\\t6.285\\t3.594\\t4.391\\t6.102\\t2'],\n"," ['17.98\\t15.85\\t0.8993\\t5.979\\t3.687\\t2.257\\t5.919\\t2'],\n"," ['20.16\\t17.03\\t0.8735\\t6.513\\t3.773\\t1.91\\t6.185\\t2'],\n"," ['17.55\\t15.66\\t0.8991\\t5.791\\t3.69\\t5.366\\t5.661\\t2'],\n"," ['18.3\\t15.89\\t0.9108\\t5.979\\t3.755\\t2.837\\t5.962\\t2'],\n"," ['18.94\\t16.32\\t0.8942\\t6.144\\t3.825\\t2.908\\t5.949\\t2'],\n"," ['15.38\\t14.9\\t0.8706\\t5.884\\t3.268\\t4.462\\t5.795\\t2'],\n"," ['16.16\\t15.33\\t0.8644\\t5.845\\t3.395\\t4.266\\t5.795\\t2'],\n"," ['15.56\\t14.89\\t0.8823\\t5.776\\t3.408\\t4.972\\t5.847\\t2'],\n"," ['15.38\\t14.66\\t0.899\\t5.477\\t3.465\\t3.6\\t5.439\\t2'],\n"," ['17.36\\t15.76\\t0.8785\\t6.145\\t3.574\\t3.526\\t5.971\\t2'],\n"," ['15.57\\t15.15\\t0.8527\\t5.92\\t3.231\\t2.64\\t5.879\\t2'],\n"," ['15.6\\t15.11\\t0.858\\t5.832\\t3.286\\t2.725\\t5.752\\t2'],\n"," ['16.23\\t15.18\\t0.885\\t5.872\\t3.472\\t3.769\\t5.922\\t2'],\n"," ['13.07\\t13.92\\t0.848\\t5.472\\t2.994\\t5.304\\t5.395\\t3'],\n"," ['13.32\\t13.94\\t0.8613\\t5.541\\t3.073\\t7.035\\t5.44\\t3'],\n"," ['13.34\\t13.95\\t0.862\\t5.389\\t3.074\\t5.995\\t5.307\\t3'],\n"," ['12.22\\t13.32\\t0.8652\\t5.224\\t2.967\\t5.469\\t5.221\\t3'],\n"," ['11.82\\t13.4\\t0.8274\\t5.314\\t2.777\\t4.471\\t5.178\\t3'],\n"," ['11.21\\t13.13\\t0.8167\\t5.279\\t2.687\\t6.169\\t5.275\\t3'],\n"," ['11.43\\t13.13\\t0.8335\\t5.176\\t2.719\\t2.221\\t5.132\\t3'],\n"," ['12.49\\t13.46\\t0.8658\\t5.267\\t2.967\\t4.421\\t5.002\\t3'],\n"," ['12.7\\t13.71\\t0.8491\\t5.386\\t2.911\\t3.26\\t5.316\\t3'],\n"," ['10.79\\t12.93\\t0.8107\\t5.317\\t2.648\\t5.462\\t5.194\\t3'],\n"," ['11.83\\t13.23\\t0.8496\\t5.263\\t2.84\\t5.195\\t5.307\\t3'],\n"," ['12.01\\t13.52\\t0.8249\\t5.405\\t2.776\\t6.992\\t5.27\\t3'],\n"," ['12.26\\t13.6\\t0.8333\\t5.408\\t2.833\\t4.756\\t5.36\\t3'],\n"," ['11.18\\t13.04\\t0.8266\\t5.22\\t2.693\\t3.332\\t5.001\\t3'],\n"," ['11.36\\t13.05\\t0.8382\\t5.175\\t2.755\\t4.048\\t5.263\\t3'],\n"," ['11.19\\t13.05\\t0.8253\\t5.25\\t2.675\\t5.813\\t5.219\\t3'],\n"," ['11.34\\t12.87\\t0.8596\\t5.053\\t2.849\\t3.347\\t5.003\\t3'],\n"," ['12.13\\t13.73\\t0.8081\\t5.394\\t2.745\\t4.825\\t5.22\\t3'],\n"," ['11.75\\t13.52\\t0.8082\\t5.444\\t2.678\\t4.378\\t5.31\\t3'],\n"," ['11.49\\t13.22\\t0.8263\\t5.304\\t2.695\\t5.388\\t5.31\\t3'],\n"," ['12.54\\t13.67\\t0.8425\\t5.451\\t2.879\\t3.082\\t5.491\\t3'],\n"," ['12.02\\t13.33\\t0.8503\\t5.35\\t2.81\\t4.271\\t5.308\\t3'],\n"," ['12.05\\t13.41\\t0.8416\\t5.267\\t2.847\\t4.988\\t5.046\\t3'],\n"," ['12.55\\t13.57\\t0.8558\\t5.333\\t2.968\\t4.419\\t5.176\\t3'],\n"," ['11.14\\t12.79\\t0.8558\\t5.011\\t2.794\\t6.388\\t5.049\\t3'],\n"," ['12.1\\t13.15\\t0.8793\\t5.105\\t2.941\\t2.201\\t5.056\\t3'],\n"," ['12.44\\t13.59\\t0.8462\\t5.319\\t2.897\\t4.924\\t5.27\\t3'],\n"," ['12.15\\t13.45\\t0.8443\\t5.417\\t2.837\\t3.638\\t5.338\\t3'],\n"," ['11.35\\t13.12\\t0.8291\\t5.176\\t2.668\\t4.337\\t5.132\\t3'],\n"," ['11.24\\t13\\t0.8359\\t5.09\\t2.715\\t3.521\\t5.088\\t3'],\n"," ['11.02\\t13\\t0.8189\\t5.325\\t2.701\\t6.735\\t5.163\\t3'],\n"," ['11.55\\t13.1\\t0.8455\\t5.167\\t2.845\\t6.715\\t4.956\\t3'],\n"," ['11.27\\t12.97\\t0.8419\\t5.088\\t2.763\\t4.309\\t5\\t3'],\n"," ['11.4\\t13.08\\t0.8375\\t5.136\\t2.763\\t5.588\\t5.089\\t3'],\n"," ['10.83\\t12.96\\t0.8099\\t5.278\\t2.641\\t5.182\\t5.185\\t3'],\n"," ['10.8\\t12.57\\t0.859\\t4.981\\t2.821\\t4.773\\t5.063\\t3'],\n"," ['11.26\\t13.01\\t0.8355\\t5.186\\t2.71\\t5.335\\t5.092\\t3'],\n"," ['10.74\\t12.73\\t0.8329\\t5.145\\t2.642\\t4.702\\t4.963\\t3'],\n"," ['11.48\\t13.05\\t0.8473\\t5.18\\t2.758\\t5.876\\t5.002\\t3'],\n"," ['12.21\\t13.47\\t0.8453\\t5.357\\t2.893\\t1.661\\t5.178\\t3'],\n"," ['11.41\\t12.95\\t0.856\\t5.09\\t2.775\\t4.957\\t4.825\\t3'],\n"," ['12.46\\t13.41\\t0.8706\\t5.236\\t3.017\\t4.987\\t5.147\\t3'],\n"," ['12.19\\t13.36\\t0.8579\\t5.24\\t2.909\\t4.857\\t5.158\\t3'],\n"," ['11.65\\t13.07\\t0.8575\\t5.108\\t2.85\\t5.209\\t5.135\\t3'],\n"," ['12.89\\t13.77\\t0.8541\\t5.495\\t3.026\\t6.185\\t5.316\\t3'],\n"," ['11.56\\t13.31\\t0.8198\\t5.363\\t2.683\\t4.062\\t5.182\\t3'],\n"," ['11.81\\t13.45\\t0.8198\\t5.413\\t2.716\\t4.898\\t5.352\\t3'],\n"," ['10.91\\t12.8\\t0.8372\\t5.088\\t2.675\\t4.179\\t4.956\\t3'],\n"," ['11.23\\t12.82\\t0.8594\\t5.089\\t2.821\\t7.524\\t4.957\\t3'],\n"," ['10.59\\t12.41\\t0.8648\\t4.899\\t2.787\\t4.975\\t4.794\\t3'],\n"," ['10.93\\t12.8\\t0.839\\t5.046\\t2.717\\t5.398\\t5.045\\t3'],\n"," ['11.27\\t12.86\\t0.8563\\t5.091\\t2.804\\t3.985\\t5.001\\t3'],\n"," ['11.87\\t13.02\\t0.8795\\t5.132\\t2.953\\t3.597\\t5.132\\t3'],\n"," ['10.82\\t12.83\\t0.8256\\t5.18\\t2.63\\t4.853\\t5.089\\t3'],\n"," ['12.11\\t13.27\\t0.8639\\t5.236\\t2.975\\t4.132\\t5.012\\t3'],\n"," ['12.8\\t13.47\\t0.886\\t5.16\\t3.126\\t4.873\\t4.914\\t3'],\n"," ['12.79\\t13.53\\t0.8786\\t5.224\\t3.054\\t5.483\\t4.958\\t3'],\n"," ['13.37\\t13.78\\t0.8849\\t5.32\\t3.128\\t4.67\\t5.091\\t3'],\n"," ['12.62\\t13.67\\t0.8481\\t5.41\\t2.911\\t3.306\\t5.231\\t3'],\n"," ['12.76\\t13.38\\t0.8964\\t5.073\\t3.155\\t2.828\\t4.83\\t3'],\n"," ['12.38\\t13.44\\t0.8609\\t5.219\\t2.989\\t5.472\\t5.045\\t3'],\n"," ['12.67\\t13.32\\t0.8977\\t4.984\\t3.135\\t2.3\\t4.745\\t3'],\n"," ['11.18\\t12.72\\t0.868\\t5.009\\t2.81\\t4.051\\t4.828\\t3'],\n"," ['12.7\\t13.41\\t0.8874\\t5.183\\t3.091\\t8.456\\t5\\t3'],\n"," ['12.37\\t13.47\\t0.8567\\t5.204\\t2.96\\t3.919\\t5.001\\t3'],\n"," ['12.19\\t13.2\\t0.8783\\t5.137\\t2.981\\t3.631\\t4.87\\t3'],\n"," ['11.23\\t12.88\\t0.8511\\t5.14\\t2.795\\t4.325\\t5.003\\t3'],\n"," ['13.2\\t13.66\\t0.8883\\t5.236\\t3.232\\t8.315\\t5.056\\t3'],\n"," ['11.84\\t13.21\\t0.8521\\t5.175\\t2.836\\t3.598\\t5.044\\t3'],\n"," ['12.3\\t13.34\\t0.8684\\t5.243\\t2.974\\t5.637\\t5.063\\t3']]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"CgrQJhYq5Z2c"},"source":["EXO 17"]},{"cell_type":"code","metadata":{"id":"ZZmbUTXmuOwa","executionInfo":{"status":"ok","timestamp":1612946853722,"user_tz":-60,"elapsed":406,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["def good_dataset(dataset):\n","  for i in range(len(dataset)):\n","    #at first we want to split each line to have several value and not one, and the delimiter\n","    #here is \"\\t\"\n","    dataset[i]=dataset[i][0].split(\"\\t\")\n","    for j in range(8):\n","      #then we convert all the value in float to be useful\n","      dataset[i][j]=float(dataset[i][j])\n","      #and then we convert the target to int because sometimes those value are use as index and index doesn't\n","      #take float value\n","    dataset[i][7]=int(dataset[i][7])\n","    dataset[i][7] = dataset[i][7]-1"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqIy6QRYvVCF","executionInfo":{"status":"ok","timestamp":1612946854820,"user_tz":-60,"elapsed":384,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"6c404849-2eb8-40a7-9a63-53238a7a1c90"},"source":["good_dataset(dataset)\n","dataset\n","#and voilaaa"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[15.26, 14.84, 0.871, 5.763, 3.312, 2.221, 5.22, 0],\n"," [14.88, 14.57, 0.8811, 5.554, 3.333, 1.018, 4.956, 0],\n"," [14.29, 14.09, 0.905, 5.291, 3.337, 2.699, 4.825, 0],\n"," [13.84, 13.94, 0.8955, 5.324, 3.379, 2.259, 4.805, 0],\n"," [16.14, 14.99, 0.9034, 5.658, 3.562, 1.355, 5.175, 0],\n"," [14.38, 14.21, 0.8951, 5.386, 3.312, 2.462, 4.956, 0],\n"," [14.69, 14.49, 0.8799, 5.563, 3.259, 3.586, 5.219, 0],\n"," [14.11, 14.1, 0.8911, 5.42, 3.302, 2.7, 5.0, 0],\n"," [16.63, 15.46, 0.8747, 6.053, 3.465, 2.04, 5.877, 0],\n"," [16.44, 15.25, 0.888, 5.884, 3.505, 1.969, 5.533, 0],\n"," [15.26, 14.85, 0.8696, 5.714, 3.242, 4.543, 5.314, 0],\n"," [14.03, 14.16, 0.8796, 5.438, 3.201, 1.717, 5.001, 0],\n"," [13.89, 14.02, 0.888, 5.439, 3.199, 3.986, 4.738, 0],\n"," [13.78, 14.06, 0.8759, 5.479, 3.156, 3.136, 4.872, 0],\n"," [13.74, 14.05, 0.8744, 5.482, 3.114, 2.932, 4.825, 0],\n"," [14.59, 14.28, 0.8993, 5.351, 3.333, 4.185, 4.781, 0],\n"," [13.99, 13.83, 0.9183, 5.119, 3.383, 5.234, 4.781, 0],\n"," [15.69, 14.75, 0.9058, 5.527, 3.514, 1.599, 5.046, 0],\n"," [14.7, 14.21, 0.9153, 5.205, 3.466, 1.767, 4.649, 0],\n"," [12.72, 13.57, 0.8686, 5.226, 3.049, 4.102, 4.914, 0],\n"," [14.16, 14.4, 0.8584, 5.658, 3.129, 3.072, 5.176, 0],\n"," [14.11, 14.26, 0.8722, 5.52, 3.168, 2.688, 5.219, 0],\n"," [15.88, 14.9, 0.8988, 5.618, 3.507, 0.7651, 5.091, 0],\n"," [12.08, 13.23, 0.8664, 5.099, 2.936, 1.415, 4.961, 0],\n"," [15.01, 14.76, 0.8657, 5.789, 3.245, 1.791, 5.001, 0],\n"," [16.19, 15.16, 0.8849, 5.833, 3.421, 0.903, 5.307, 0],\n"," [13.02, 13.76, 0.8641, 5.395, 3.026, 3.373, 4.825, 0],\n"," [12.74, 13.67, 0.8564, 5.395, 2.956, 2.504, 4.869, 0],\n"," [14.11, 14.18, 0.882, 5.541, 3.221, 2.754, 5.038, 0],\n"," [13.45, 14.02, 0.8604, 5.516, 3.065, 3.531, 5.097, 0],\n"," [13.16, 13.82, 0.8662, 5.454, 2.975, 0.8551, 5.056, 0],\n"," [15.49, 14.94, 0.8724, 5.757, 3.371, 3.412, 5.228, 0],\n"," [14.09, 14.41, 0.8529, 5.717, 3.186, 3.92, 5.299, 0],\n"," [13.94, 14.17, 0.8728, 5.585, 3.15, 2.124, 5.012, 0],\n"," [15.05, 14.68, 0.8779, 5.712, 3.328, 2.129, 5.36, 0],\n"," [16.12, 15.0, 0.9, 5.709, 3.485, 2.27, 5.443, 0],\n"," [16.2, 15.27, 0.8734, 5.826, 3.464, 2.823, 5.527, 0],\n"," [17.08, 15.38, 0.9079, 5.832, 3.683, 2.956, 5.484, 0],\n"," [14.8, 14.52, 0.8823, 5.656, 3.288, 3.112, 5.309, 0],\n"," [14.28, 14.17, 0.8944, 5.397, 3.298, 6.685, 5.001, 0],\n"," [13.54, 13.85, 0.8871, 5.348, 3.156, 2.587, 5.178, 0],\n"," [13.5, 13.85, 0.8852, 5.351, 3.158, 2.249, 5.176, 0],\n"," [13.16, 13.55, 0.9009, 5.138, 3.201, 2.461, 4.783, 0],\n"," [15.5, 14.86, 0.882, 5.877, 3.396, 4.711, 5.528, 0],\n"," [15.11, 14.54, 0.8986, 5.579, 3.462, 3.128, 5.18, 0],\n"," [13.8, 14.04, 0.8794, 5.376, 3.155, 1.56, 4.961, 0],\n"," [15.36, 14.76, 0.8861, 5.701, 3.393, 1.367, 5.132, 0],\n"," [14.99, 14.56, 0.8883, 5.57, 3.377, 2.958, 5.175, 0],\n"," [14.79, 14.52, 0.8819, 5.545, 3.291, 2.704, 5.111, 0],\n"," [14.86, 14.67, 0.8676, 5.678, 3.258, 2.129, 5.351, 0],\n"," [14.43, 14.4, 0.8751, 5.585, 3.272, 3.975, 5.144, 0],\n"," [15.78, 14.91, 0.8923, 5.674, 3.434, 5.593, 5.136, 0],\n"," [14.49, 14.61, 0.8538, 5.715, 3.113, 4.116, 5.396, 0],\n"," [14.33, 14.28, 0.8831, 5.504, 3.199, 3.328, 5.224, 0],\n"," [14.52, 14.6, 0.8557, 5.741, 3.113, 1.481, 5.487, 0],\n"," [15.03, 14.77, 0.8658, 5.702, 3.212, 1.933, 5.439, 0],\n"," [14.46, 14.35, 0.8818, 5.388, 3.377, 2.802, 5.044, 0],\n"," [14.92, 14.43, 0.9006, 5.384, 3.412, 1.142, 5.088, 0],\n"," [15.38, 14.77, 0.8857, 5.662, 3.419, 1.999, 5.222, 0],\n"," [12.11, 13.47, 0.8392, 5.159, 3.032, 1.502, 4.519, 0],\n"," [11.42, 12.86, 0.8683, 5.008, 2.85, 2.7, 4.607, 0],\n"," [11.23, 12.63, 0.884, 4.902, 2.879, 2.269, 4.703, 0],\n"," [12.36, 13.19, 0.8923, 5.076, 3.042, 3.22, 4.605, 0],\n"," [13.22, 13.84, 0.868, 5.395, 3.07, 4.157, 5.088, 0],\n"," [12.78, 13.57, 0.8716, 5.262, 3.026, 1.176, 4.782, 0],\n"," [12.88, 13.5, 0.8879, 5.139, 3.119, 2.352, 4.607, 0],\n"," [14.34, 14.37, 0.8726, 5.63, 3.19, 1.313, 5.15, 0],\n"," [14.01, 14.29, 0.8625, 5.609, 3.158, 2.217, 5.132, 0],\n"," [14.37, 14.39, 0.8726, 5.569, 3.153, 1.464, 5.3, 0],\n"," [12.73, 13.75, 0.8458, 5.412, 2.882, 3.533, 5.067, 0],\n"," [17.63, 15.98, 0.8673, 6.191, 3.561, 4.076, 6.06, 1],\n"," [16.84, 15.67, 0.8623, 5.998, 3.484, 4.675, 5.877, 1],\n"," [17.26, 15.73, 0.8763, 5.978, 3.594, 4.539, 5.791, 1],\n"," [19.11, 16.26, 0.9081, 6.154, 3.93, 2.936, 6.079, 1],\n"," [16.82, 15.51, 0.8786, 6.017, 3.486, 4.004, 5.841, 1],\n"," [16.77, 15.62, 0.8638, 5.927, 3.438, 4.92, 5.795, 1],\n"," [17.32, 15.91, 0.8599, 6.064, 3.403, 3.824, 5.922, 1],\n"," [20.71, 17.23, 0.8763, 6.579, 3.814, 4.451, 6.451, 1],\n"," [18.94, 16.49, 0.875, 6.445, 3.639, 5.064, 6.362, 1],\n"," [17.12, 15.55, 0.8892, 5.85, 3.566, 2.858, 5.746, 1],\n"," [16.53, 15.34, 0.8823, 5.875, 3.467, 5.532, 5.88, 1],\n"," [18.72, 16.19, 0.8977, 6.006, 3.857, 5.324, 5.879, 1],\n"," [20.2, 16.89, 0.8894, 6.285, 3.864, 5.173, 6.187, 1],\n"," [19.57, 16.74, 0.8779, 6.384, 3.772, 1.472, 6.273, 1],\n"," [19.51, 16.71, 0.878, 6.366, 3.801, 2.962, 6.185, 1],\n"," [18.27, 16.09, 0.887, 6.173, 3.651, 2.443, 6.197, 1],\n"," [18.88, 16.26, 0.8969, 6.084, 3.764, 1.649, 6.109, 1],\n"," [18.98, 16.66, 0.859, 6.549, 3.67, 3.691, 6.498, 1],\n"," [21.18, 17.21, 0.8989, 6.573, 4.033, 5.78, 6.231, 1],\n"," [20.88, 17.05, 0.9031, 6.45, 4.032, 5.016, 6.321, 1],\n"," [20.1, 16.99, 0.8746, 6.581, 3.785, 1.955, 6.449, 1],\n"," [18.76, 16.2, 0.8984, 6.172, 3.796, 3.12, 6.053, 1],\n"," [18.81, 16.29, 0.8906, 6.272, 3.693, 3.237, 6.053, 1],\n"," [18.59, 16.05, 0.9066, 6.037, 3.86, 6.001, 5.877, 1],\n"," [18.36, 16.52, 0.8452, 6.666, 3.485, 4.933, 6.448, 1],\n"," [16.87, 15.65, 0.8648, 6.139, 3.463, 3.696, 5.967, 1],\n"," [19.31, 16.59, 0.8815, 6.341, 3.81, 3.477, 6.238, 1],\n"," [18.98, 16.57, 0.8687, 6.449, 3.552, 2.144, 6.453, 1],\n"," [18.17, 16.26, 0.8637, 6.271, 3.512, 2.853, 6.273, 1],\n"," [18.72, 16.34, 0.881, 6.219, 3.684, 2.188, 6.097, 1],\n"," [16.41, 15.25, 0.8866, 5.718, 3.525, 4.217, 5.618, 1],\n"," [17.99, 15.86, 0.8992, 5.89, 3.694, 2.068, 5.837, 1],\n"," [19.46, 16.5, 0.8985, 6.113, 3.892, 4.308, 6.009, 1],\n"," [19.18, 16.63, 0.8717, 6.369, 3.681, 3.357, 6.229, 1],\n"," [18.95, 16.42, 0.8829, 6.248, 3.755, 3.368, 6.148, 1],\n"," [18.83, 16.29, 0.8917, 6.037, 3.786, 2.553, 5.879, 1],\n"," [18.85, 16.17, 0.9056, 6.152, 3.806, 2.843, 6.2, 1],\n"," [17.63, 15.86, 0.88, 6.033, 3.573, 3.747, 5.929, 1],\n"," [19.94, 16.92, 0.8752, 6.675, 3.763, 3.252, 6.55, 1],\n"," [18.55, 16.22, 0.8865, 6.153, 3.674, 1.738, 5.894, 1],\n"," [18.45, 16.12, 0.8921, 6.107, 3.769, 2.235, 5.794, 1],\n"," [19.38, 16.72, 0.8716, 6.303, 3.791, 3.678, 5.965, 1],\n"," [19.13, 16.31, 0.9035, 6.183, 3.902, 2.109, 5.924, 1],\n"," [19.14, 16.61, 0.8722, 6.259, 3.737, 6.682, 6.053, 1],\n"," [20.97, 17.25, 0.8859, 6.563, 3.991, 4.677, 6.316, 1],\n"," [19.06, 16.45, 0.8854, 6.416, 3.719, 2.248, 6.163, 1],\n"," [18.96, 16.2, 0.9077, 6.051, 3.897, 4.334, 5.75, 1],\n"," [19.15, 16.45, 0.889, 6.245, 3.815, 3.084, 6.185, 1],\n"," [18.89, 16.23, 0.9008, 6.227, 3.769, 3.639, 5.966, 1],\n"," [20.03, 16.9, 0.8811, 6.493, 3.857, 3.063, 6.32, 1],\n"," [20.24, 16.91, 0.8897, 6.315, 3.962, 5.901, 6.188, 1],\n"," [18.14, 16.12, 0.8772, 6.059, 3.563, 3.619, 6.011, 1],\n"," [16.17, 15.38, 0.8588, 5.762, 3.387, 4.286, 5.703, 1],\n"," [18.43, 15.97, 0.9077, 5.98, 3.771, 2.984, 5.905, 1],\n"," [15.99, 14.89, 0.9064, 5.363, 3.582, 3.336, 5.144, 1],\n"," [18.75, 16.18, 0.8999, 6.111, 3.869, 4.188, 5.992, 1],\n"," [18.65, 16.41, 0.8698, 6.285, 3.594, 4.391, 6.102, 1],\n"," [17.98, 15.85, 0.8993, 5.979, 3.687, 2.257, 5.919, 1],\n"," [20.16, 17.03, 0.8735, 6.513, 3.773, 1.91, 6.185, 1],\n"," [17.55, 15.66, 0.8991, 5.791, 3.69, 5.366, 5.661, 1],\n"," [18.3, 15.89, 0.9108, 5.979, 3.755, 2.837, 5.962, 1],\n"," [18.94, 16.32, 0.8942, 6.144, 3.825, 2.908, 5.949, 1],\n"," [15.38, 14.9, 0.8706, 5.884, 3.268, 4.462, 5.795, 1],\n"," [16.16, 15.33, 0.8644, 5.845, 3.395, 4.266, 5.795, 1],\n"," [15.56, 14.89, 0.8823, 5.776, 3.408, 4.972, 5.847, 1],\n"," [15.38, 14.66, 0.899, 5.477, 3.465, 3.6, 5.439, 1],\n"," [17.36, 15.76, 0.8785, 6.145, 3.574, 3.526, 5.971, 1],\n"," [15.57, 15.15, 0.8527, 5.92, 3.231, 2.64, 5.879, 1],\n"," [15.6, 15.11, 0.858, 5.832, 3.286, 2.725, 5.752, 1],\n"," [16.23, 15.18, 0.885, 5.872, 3.472, 3.769, 5.922, 1],\n"," [13.07, 13.92, 0.848, 5.472, 2.994, 5.304, 5.395, 2],\n"," [13.32, 13.94, 0.8613, 5.541, 3.073, 7.035, 5.44, 2],\n"," [13.34, 13.95, 0.862, 5.389, 3.074, 5.995, 5.307, 2],\n"," [12.22, 13.32, 0.8652, 5.224, 2.967, 5.469, 5.221, 2],\n"," [11.82, 13.4, 0.8274, 5.314, 2.777, 4.471, 5.178, 2],\n"," [11.21, 13.13, 0.8167, 5.279, 2.687, 6.169, 5.275, 2],\n"," [11.43, 13.13, 0.8335, 5.176, 2.719, 2.221, 5.132, 2],\n"," [12.49, 13.46, 0.8658, 5.267, 2.967, 4.421, 5.002, 2],\n"," [12.7, 13.71, 0.8491, 5.386, 2.911, 3.26, 5.316, 2],\n"," [10.79, 12.93, 0.8107, 5.317, 2.648, 5.462, 5.194, 2],\n"," [11.83, 13.23, 0.8496, 5.263, 2.84, 5.195, 5.307, 2],\n"," [12.01, 13.52, 0.8249, 5.405, 2.776, 6.992, 5.27, 2],\n"," [12.26, 13.6, 0.8333, 5.408, 2.833, 4.756, 5.36, 2],\n"," [11.18, 13.04, 0.8266, 5.22, 2.693, 3.332, 5.001, 2],\n"," [11.36, 13.05, 0.8382, 5.175, 2.755, 4.048, 5.263, 2],\n"," [11.19, 13.05, 0.8253, 5.25, 2.675, 5.813, 5.219, 2],\n"," [11.34, 12.87, 0.8596, 5.053, 2.849, 3.347, 5.003, 2],\n"," [12.13, 13.73, 0.8081, 5.394, 2.745, 4.825, 5.22, 2],\n"," [11.75, 13.52, 0.8082, 5.444, 2.678, 4.378, 5.31, 2],\n"," [11.49, 13.22, 0.8263, 5.304, 2.695, 5.388, 5.31, 2],\n"," [12.54, 13.67, 0.8425, 5.451, 2.879, 3.082, 5.491, 2],\n"," [12.02, 13.33, 0.8503, 5.35, 2.81, 4.271, 5.308, 2],\n"," [12.05, 13.41, 0.8416, 5.267, 2.847, 4.988, 5.046, 2],\n"," [12.55, 13.57, 0.8558, 5.333, 2.968, 4.419, 5.176, 2],\n"," [11.14, 12.79, 0.8558, 5.011, 2.794, 6.388, 5.049, 2],\n"," [12.1, 13.15, 0.8793, 5.105, 2.941, 2.201, 5.056, 2],\n"," [12.44, 13.59, 0.8462, 5.319, 2.897, 4.924, 5.27, 2],\n"," [12.15, 13.45, 0.8443, 5.417, 2.837, 3.638, 5.338, 2],\n"," [11.35, 13.12, 0.8291, 5.176, 2.668, 4.337, 5.132, 2],\n"," [11.24, 13.0, 0.8359, 5.09, 2.715, 3.521, 5.088, 2],\n"," [11.02, 13.0, 0.8189, 5.325, 2.701, 6.735, 5.163, 2],\n"," [11.55, 13.1, 0.8455, 5.167, 2.845, 6.715, 4.956, 2],\n"," [11.27, 12.97, 0.8419, 5.088, 2.763, 4.309, 5.0, 2],\n"," [11.4, 13.08, 0.8375, 5.136, 2.763, 5.588, 5.089, 2],\n"," [10.83, 12.96, 0.8099, 5.278, 2.641, 5.182, 5.185, 2],\n"," [10.8, 12.57, 0.859, 4.981, 2.821, 4.773, 5.063, 2],\n"," [11.26, 13.01, 0.8355, 5.186, 2.71, 5.335, 5.092, 2],\n"," [10.74, 12.73, 0.8329, 5.145, 2.642, 4.702, 4.963, 2],\n"," [11.48, 13.05, 0.8473, 5.18, 2.758, 5.876, 5.002, 2],\n"," [12.21, 13.47, 0.8453, 5.357, 2.893, 1.661, 5.178, 2],\n"," [11.41, 12.95, 0.856, 5.09, 2.775, 4.957, 4.825, 2],\n"," [12.46, 13.41, 0.8706, 5.236, 3.017, 4.987, 5.147, 2],\n"," [12.19, 13.36, 0.8579, 5.24, 2.909, 4.857, 5.158, 2],\n"," [11.65, 13.07, 0.8575, 5.108, 2.85, 5.209, 5.135, 2],\n"," [12.89, 13.77, 0.8541, 5.495, 3.026, 6.185, 5.316, 2],\n"," [11.56, 13.31, 0.8198, 5.363, 2.683, 4.062, 5.182, 2],\n"," [11.81, 13.45, 0.8198, 5.413, 2.716, 4.898, 5.352, 2],\n"," [10.91, 12.8, 0.8372, 5.088, 2.675, 4.179, 4.956, 2],\n"," [11.23, 12.82, 0.8594, 5.089, 2.821, 7.524, 4.957, 2],\n"," [10.59, 12.41, 0.8648, 4.899, 2.787, 4.975, 4.794, 2],\n"," [10.93, 12.8, 0.839, 5.046, 2.717, 5.398, 5.045, 2],\n"," [11.27, 12.86, 0.8563, 5.091, 2.804, 3.985, 5.001, 2],\n"," [11.87, 13.02, 0.8795, 5.132, 2.953, 3.597, 5.132, 2],\n"," [10.82, 12.83, 0.8256, 5.18, 2.63, 4.853, 5.089, 2],\n"," [12.11, 13.27, 0.8639, 5.236, 2.975, 4.132, 5.012, 2],\n"," [12.8, 13.47, 0.886, 5.16, 3.126, 4.873, 4.914, 2],\n"," [12.79, 13.53, 0.8786, 5.224, 3.054, 5.483, 4.958, 2],\n"," [13.37, 13.78, 0.8849, 5.32, 3.128, 4.67, 5.091, 2],\n"," [12.62, 13.67, 0.8481, 5.41, 2.911, 3.306, 5.231, 2],\n"," [12.76, 13.38, 0.8964, 5.073, 3.155, 2.828, 4.83, 2],\n"," [12.38, 13.44, 0.8609, 5.219, 2.989, 5.472, 5.045, 2],\n"," [12.67, 13.32, 0.8977, 4.984, 3.135, 2.3, 4.745, 2],\n"," [11.18, 12.72, 0.868, 5.009, 2.81, 4.051, 4.828, 2],\n"," [12.7, 13.41, 0.8874, 5.183, 3.091, 8.456, 5.0, 2],\n"," [12.37, 13.47, 0.8567, 5.204, 2.96, 3.919, 5.001, 2],\n"," [12.19, 13.2, 0.8783, 5.137, 2.981, 3.631, 4.87, 2],\n"," [11.23, 12.88, 0.8511, 5.14, 2.795, 4.325, 5.003, 2],\n"," [13.2, 13.66, 0.8883, 5.236, 3.232, 8.315, 5.056, 2],\n"," [11.84, 13.21, 0.8521, 5.175, 2.836, 3.598, 5.044, 2],\n"," [12.3, 13.34, 0.8684, 5.243, 2.974, 5.637, 5.063, 2]]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"xW9Htv4qzcf1","executionInfo":{"status":"ok","timestamp":1612946857970,"user_tz":-60,"elapsed":444,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#then we scale the dataset with the minmax formula :\n","#xi = (xi-min(x))/(max(x)-min(x))\n","def scale(dataset):\n","  for i in range(len(dataset)):\n","    for j in range(7):\n","      dataset[i][j] = (dataset[i][j]-min(dataset[i][:-1]))/(max(dataset[i][:-1])-min(dataset[i][:-1]))"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"lugaJ2lszxNi","executionInfo":{"status":"ok","timestamp":1612946859330,"user_tz":-60,"elapsed":423,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["scale(dataset)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qFlS_QH3cCH","executionInfo":{"status":"ok","timestamp":1612946860618,"user_tz":-60,"elapsed":413,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["#then we split the dataset into a 80/20 rate\n","def train_test_split(dataset):\n","  train_rate = int(0.8*len(dataset))\n","  train = dataset[:train_rate]\n","  test = dataset[train_rate:]\n","  return train, test"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"cheR1Ueb3dkB","executionInfo":{"status":"ok","timestamp":1612946863014,"user_tz":-60,"elapsed":502,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}}},"source":["train, test = train_test_split(dataset)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"718pYJt45da6"},"source":["EXO 18"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5KkBjQy5eUa","executionInfo":{"status":"ok","timestamp":1612946873870,"user_tz":-60,"elapsed":436,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"19da3022-1b07-4381-e0d6-795ab219ecfd"},"source":["#we initialize the network and train our network\n","network = initialize_network(7,5,3)\n","train_network(network, train,0.5, 20, 3)"],"execution_count":32,"outputs":[{"output_type":"stream","text":[">epoch=0, lrate=0.500, error=100.141\n",">epoch=1, lrate=0.500, error=50.246\n",">epoch=2, lrate=0.500, error=51.734\n",">epoch=3, lrate=0.500, error=51.691\n",">epoch=4, lrate=0.500, error=51.654\n",">epoch=5, lrate=0.500, error=51.625\n",">epoch=6, lrate=0.500, error=51.598\n",">epoch=7, lrate=0.500, error=51.557\n",">epoch=8, lrate=0.500, error=51.427\n",">epoch=9, lrate=0.500, error=51.021\n",">epoch=10, lrate=0.500, error=51.082\n",">epoch=11, lrate=0.500, error=51.715\n",">epoch=12, lrate=0.500, error=51.869\n",">epoch=13, lrate=0.500, error=51.806\n",">epoch=14, lrate=0.500, error=51.694\n",">epoch=15, lrate=0.500, error=51.589\n",">epoch=16, lrate=0.500, error=51.515\n",">epoch=17, lrate=0.500, error=51.478\n",">epoch=18, lrate=0.500, error=51.474\n",">epoch=19, lrate=0.500, error=51.488\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-j59K6wH9iRI"},"source":["EXO 19"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjIjslue9XcB","executionInfo":{"status":"ok","timestamp":1612946878417,"user_tz":-60,"elapsed":412,"user":{"displayName":"Drevet Lucie","photoUrl":"","userId":"00158076378068614037"}},"outputId":"d5174804-97eb-47e6-95cf-22304e1ec62b"},"source":["#and finally we try to predict the value from the test set\n","for row in dataset:\n","\tprediction = predict(network, row)\n","\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=0, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=1, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n","Expected=2, Got=2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y0e2Y4ft9kwk"},"source":[""],"execution_count":null,"outputs":[]}]}